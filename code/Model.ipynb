{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f9bde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.Pipeline import label_feature_data_and_merge\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "caf7af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = \"/Users/sanjaydutt/Documents/CSC503_project/data/\"\n",
    "METHOD_LEVEL_REFACTORINGS = [\n",
    "    \"Extract And Move Method\",\n",
    "    \"Extract Method\",\n",
    "    \"Inline Method\",\n",
    "    \"Move Method\",\n",
    "    \"Pull Up Method\",\n",
    "    \"Push Down Method\",\n",
    "    \"Rename Method\",\n",
    "    \"Extract And Move Method\",\n",
    "    \"Change Return Type\",\n",
    "    \"Move And Inline Method\",\n",
    "    \"Move And Rename Method\",\n",
    "    \"Change Parameter Type\",\n",
    "    \"Split Parameter\",\n",
    "    \"Merge Parameter\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24cec3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cache_data_and_preprocess_it(refactored_file_path, non_refactored_file_path):\n",
    "    \n",
    "    refactored_data = pd.read_feather(refactored_file_path)\n",
    "    refactored_data.set_index(\"index\", inplace=True)\n",
    "    \n",
    "    non_refactored_data = pd.read_feather(non_refactored_file_path)\n",
    "    non_refactored_data.set_index(\"index\", inplace=True)\n",
    "    \n",
    "    data = label_feature_data_and_merge(refactored_data, non_refactored_data)\n",
    "    y = data[\"refactored\"]\n",
    "    x = data.drop(\"refactored\", axis=1)\n",
    "    \n",
    "    print(y.value_counts())\n",
    "    \n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c39f8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PICK first refactoring metric\n",
    "refactored_file_path = ''.join([CACHE_DIR, ''.join(METHOD_LEVEL_REFACTORINGS[0].lower().split()), '.ftr'])\n",
    "non_refactored_file_path = '/Users/sanjaydutt/Documents/CSC503_project/data/nonrefactoreddata.ftr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3aa9b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    66803\n",
      "1    29946\n",
      "Name: refactored, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "(x, y) = load_cache_data_and_preprocess_it(refactored_file_path, non_refactored_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8ca72cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "77f23d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3777febd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 30 is smaller than n_iter=100. Running 30 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=LogisticRegression(random_state=20, solver='saga'),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'C': [21.232131688717615,\n",
       "                                              79.94012516306755,\n",
       "                                              40.6990195703418,\n",
       "                                              44.69252303240279,\n",
       "                                              35.58661877888244],\n",
       "                                        'max_iter': [100, 500, 1000, 2000, 5000,\n",
       "                                                     10000]},\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_logistic_regression_model_random_cv().fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8b8e80aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=21.232131688717615, max_iter=5000, random_state=20,\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "97699f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from random import uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "class DecisionTreeRefactoringModel:\n",
    "\n",
    "    def params_to_tune(self):\n",
    "        return {\"max_depth\": [3, 6, 9, 12, 16],\n",
    "                \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "                \"min_samples_leaf\": [1,10, 100],\n",
    "                \"min_samples_split\": [2, 4, 10],\n",
    "                \"splitter\": [\"best\", \"random\"],\n",
    "                \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "    def model(self, best_params=None):\n",
    "        if best_params is not None:\n",
    "            return DecisionTreeClassifier(\n",
    "                random_state=SEED,\n",
    "                max_depth=best_params[\"max_depth\"],\n",
    "                max_features=best_params[\"max_features\"],\n",
    "                min_samples_split=best_params[\"min_samples_split\"],\n",
    "                min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "                splitter=best_params[\"splitter\"],\n",
    "                criterion=best_params[\"criterion\"])\n",
    "\n",
    "        return DecisionTreeClassifier(random_state=20)\n",
    "    \n",
    "class LogisticRegressionRefactoringModel():\n",
    "    def feature_reduction(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def params_to_tune(self):\n",
    "        return {\n",
    "            \"max_iter\": [100, 500, 1000],\n",
    "            \"C\": [uniform(0.01, 100) for i in range(0, 5)]}\n",
    "\n",
    "    def model(self, best_params=None):\n",
    "        if best_params is not None:\n",
    "            return LogisticRegression(\n",
    "                solver='saga',\n",
    "                max_iter=best_params[\"max_iter\"],\n",
    "                C=best_params[\"C\"],\n",
    "                n_jobs=CORE_COUNT,\n",
    "                random_state=SEED)\n",
    "        return LogisticRegression(solver='saga', random_state=20)\n",
    "\n",
    "class RandomForestRefactoringModel():\n",
    "    def feature_reduction(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    def params_to_tune(self):\n",
    "        return {\n",
    "            \"max_depth\": [3, 6, 12, 24, None],\n",
    "            \"max_features\": [\"auto\", \"log2\", None],\n",
    "            \"min_samples_split\": [2, 3, 4, 5, 10],\n",
    "            \"bootstrap\": [True, False],\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"n_estimators\": [10, 50, 100, 150, 200]\n",
    "        }\n",
    "\n",
    "    def model(self, best_params=None):\n",
    "        if best_params is not None:\n",
    "            return RandomForestClassifier(\n",
    "                random_state=SEED,\n",
    "                n_jobs=CORE_COUNT,\n",
    "                max_depth=best_params[\"max_depth\"],\n",
    "                max_features=best_params[\"max_features\"],\n",
    "                min_samples_split=best_params[\"min_samples_split\"],\n",
    "                bootstrap=best_params[\"bootstrap\"],\n",
    "                criterion=best_params[\"criterion\"],\n",
    "                n_estimators=best_params[\"n_estimators\"],\n",
    "            )\n",
    "\n",
    "        return RandomForestClassifier(random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "75737166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision_tree_model_random_cv():\n",
    "    decisionTree = DecisionTreeRefactoringModel()\n",
    "    model = decisionTree.model()\n",
    "    param_dist = decisionTree.params_to_tune()\n",
    "    search = RandomizedSearchCV(\n",
    "                model,\n",
    "                param_dist,\n",
    "                n_iter=100,\n",
    "                cv=StratifiedKFold(\n",
    "                    n_splits=5,\n",
    "                    shuffle=True),\n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                verbose=1)\n",
    "    return search\n",
    "\n",
    "def get_random_forest_tree_model_random_cv():\n",
    "    randomForest = RandomForestRefactoringModel()\n",
    "    model = randomForest.model()\n",
    "    param_dist = randomForest.params_to_tune()\n",
    "    search = RandomizedSearchCV(\n",
    "                model,\n",
    "                param_dist,\n",
    "                n_iter=100,\n",
    "                cv=StratifiedKFold(\n",
    "                    n_splits=5,\n",
    "                    shuffle=True),\n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                verbose=1)\n",
    "    return search\n",
    "def get_logistic_regression_model_random_cv():\n",
    "    logisticReg = LogisticRegressionRefactoringModel()\n",
    "    model = logisticReg.model()\n",
    "    param_dist = logisticReg.params_to_tune()\n",
    "    search = RandomizedSearchCV(\n",
    "                model,\n",
    "                param_dist,\n",
    "                n_iter=100,\n",
    "                cv=StratifiedKFold(\n",
    "                    n_splits=5,\n",
    "                    shuffle=True),\n",
    "                scoring=\"accuracy\",\n",
    "                n_jobs=-1,\n",
    "                verbose=1)\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1abd9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_method_refactoring_1():\n",
    "    non_refactored_file_path = 'data/nonrefactoreddata.ftr'\n",
    "    for method_refactoring in METHOD_LEVEL_REFACTORINGS:\n",
    "        print(\"=================================\")\n",
    "        print(\"Best Model is finding for\", method_refactoring)\n",
    "        \n",
    "        # PICK first refactoring metric\n",
    "        refactored_file_path = ''.join(['data/', ''.join(method_refactoring.lower().split()), '.ftr'])\n",
    "        print(refactored_file_path)\n",
    "        (x, y) = load_cache_data_and_preprocess_it(refactored_file_path, non_refactored_file_path)\n",
    "        \n",
    "        print(\"The shape of sample is\", x.shape)\n",
    "        print(\"Number of sample in different classes before sampling\")\n",
    "        print(y.value_counts())\n",
    "        \n",
    "        undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "        X_over, y_over = undersample.fit_resample(x, y)\n",
    "        \n",
    "        print(\"Number of sample in different classes after sampling\")\n",
    "        print(y_over.value_counts())\n",
    "        \n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(X_over, y_over, test_size=0.20, random_state=42)\n",
    "        \n",
    "        randomizedCVModel = get_decision_tree_model_random_cv()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        randomizedCVModel.fit(X_train, y_train)\n",
    "        print(\"The training time:\", time.time() - t0)\n",
    "        best_estimator = randomizedCVModel.best_estimator_\n",
    "        \n",
    "        t1 = time.time()\n",
    "        y_pred = best_estimator.predict(X_test)\n",
    "        print(\"The validation time:\", time.time() - t1)\n",
    "        \n",
    "        print(\"The accuracy of the model\", best_estimator.score(X_test, y_test))\n",
    "        print(\"Recall score is\", recall_score(y_test, best_estimator.predict(X_test)))\n",
    "        print(\"Precision score is\", precision_score(y_test, best_estimator.predict(X_test)))\n",
    "              \n",
    "        print(search.best_estimator_)\n",
    "        print(search.best_params_)\n",
    "        print(search.best_score_)\n",
    "        \n",
    "        print(\"Feature Importance\")\n",
    "        # result = permutation_importance(best_estimator, X_train, y_train, n_repeats=10,random_state=0)\n",
    "        # print(result)\n",
    "        print(\"=================================\")\n",
    "        \n",
    "        r = permutation_importance(best_estimator, X_train, y_train, n_repeats=30,random_state=0)\n",
    "        count = 0\n",
    "        for i in r.importances_mean.argsort()[::-1]:\n",
    "            if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "                count = count + 1\n",
    "                print(f\"{X_train.columns[i]:<8}\"\n",
    "                    f\"{r.importances_mean[i]:.3f}\"\n",
    "                        f\" +/- {r.importances_std[i]:.3f}\")\n",
    "                if count >= 10:\n",
    "                    break\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7c8fe91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Best Model is finding for Extract And Move Method\n",
      "data/extractandmovemethod.ftr\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (75440, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    8637\n",
      "1    8637\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 7.674571990966797\n",
      "The validation time: 0.003090381622314453\n",
      "The accuracy of the model 0.8819102749638206\n",
      "Recall score is 0.89171974522293\n",
      "Precision score is 0.8745031232254401\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "methodRfc0.150 +/- 0.002\n",
      "startLine0.144 +/- 0.002\n",
      "methodLoc0.142 +/- 0.002\n",
      "qtyOfCommits0.101 +/- 0.002\n",
      "classUniqueWordsQty0.095 +/- 0.002\n",
      "refactoringsInvolved0.070 +/- 0.001\n",
      "methodVariablesQty0.049 +/- 0.001\n",
      "classTCC0.048 +/- 0.001\n",
      "authorOwnership0.043 +/- 0.001\n",
      "classStringLiteralsQty0.042 +/- 0.001\n",
      "=================================\n",
      "Best Model is finding for Extract Method\n",
      "data/extractmethod.ftr\n",
      "0    66803\n",
      "1    29946\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (96749, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    29946\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    29946\n",
      "1    29946\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 19.576860904693604\n",
      "The validation time: 0.005542278289794922\n",
      "The accuracy of the model 0.9036647466399532\n",
      "Recall score is 0.9071841453344344\n",
      "Precision score is 0.9027115858668858\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "methodLoc0.139 +/- 0.001\n",
      "qtyOfCommits0.122 +/- 0.001\n",
      "startLine0.104 +/- 0.001\n",
      "authorOwnership0.093 +/- 0.001\n",
      "refactoringsInvolved0.090 +/- 0.001\n",
      "classUniqueWordsQty0.059 +/- 0.001\n",
      "methodRfc0.056 +/- 0.001\n",
      "classNumberOfPublicMethods0.052 +/- 0.001\n",
      "classCbo0.030 +/- 0.001\n",
      "classLcom0.025 +/- 0.000\n",
      "=================================\n",
      "Best Model is finding for Inline Method\n",
      "data/inlinemethod.ftr\n",
      "0    66803\n",
      "1     7098\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (73901, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     7098\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    7098\n",
      "1    7098\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 3.2269811630249023\n",
      "The validation time: 0.0033168792724609375\n",
      "The accuracy of the model 0.897887323943662\n",
      "Recall score is 0.923836389280677\n",
      "Precision score is 0.8780160857908847\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "classWmc0.175 +/- 0.003\n",
      "classNumberOfMethods0.123 +/- 0.002\n",
      "classNumberOfPrivateFields0.117 +/- 0.002\n",
      "startLine0.113 +/- 0.003\n",
      "classLcom0.078 +/- 0.002\n",
      "bugFixCount0.074 +/- 0.002\n",
      "qtyOfCommits0.068 +/- 0.002\n",
      "qtyOfAuthors0.060 +/- 0.002\n",
      "classNumberOfPrivateMethods0.052 +/- 0.001\n",
      "classCbo0.052 +/- 0.002\n",
      "=================================\n",
      "Best Model is finding for Move Method\n",
      "data/movemethod.ftr\n",
      "0    66803\n",
      "1    23835\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (90638, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    23835\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    23835\n",
      "1    23835\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 14.66811203956604\n",
      "The validation time: 0.0072367191314697266\n",
      "The accuracy of the model 0.9400041955108034\n",
      "Recall score is 0.9422240629529923\n",
      "Precision score is 0.9395003097253768\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "qtyOfCommits0.210 +/- 0.002\n",
      "refactoringsInvolved0.197 +/- 0.002\n",
      "startLine0.136 +/- 0.002\n",
      "authorOwnership0.129 +/- 0.002\n",
      "classLoc0.116 +/- 0.001\n",
      "classNumberOfMethods0.110 +/- 0.001\n",
      "classUniqueWordsQty0.102 +/- 0.001\n",
      "classNumberOfPrivateMethods0.098 +/- 0.001\n",
      "classLcom0.077 +/- 0.001\n",
      "bugFixCount0.065 +/- 0.001\n",
      "=================================\n",
      "Best Model is finding for Pull Up Method\n",
      "data/pullupmethod.ftr\n",
      "0    66803\n",
      "1    14062\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (80865, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    14062\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    14062\n",
      "1    14062\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 7.157304763793945\n",
      "The validation time: 0.004055023193359375\n",
      "The accuracy of the model 0.9457777777777778\n",
      "Recall score is 0.9564111877951326\n",
      "Precision score is 0.9343506032647267\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "refactoringsInvolved0.249 +/- 0.002\n",
      "qtyOfCommits0.247 +/- 0.002\n",
      "startLine0.166 +/- 0.002\n",
      "authorOwnership0.096 +/- 0.001\n",
      "classNumberOfStaticMethods0.061 +/- 0.001\n",
      "classLcom0.056 +/- 0.001\n",
      "classCbo0.050 +/- 0.001\n",
      "bugFixCount0.045 +/- 0.001\n",
      "classUniqueWordsQty0.044 +/- 0.001\n",
      "qtyMinorAuthors0.040 +/- 0.001\n",
      "=================================\n",
      "Best Model is finding for Push Down Method\n",
      "data/pushdownmethod.ftr\n",
      "0    66803\n",
      "1     8039\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (74842, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     8039\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    8039\n",
      "1    8039\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 3.9429428577423096\n",
      "The validation time: 0.002366781234741211\n",
      "The accuracy of the model 0.9390547263681592\n",
      "Recall score is 0.9623456790123457\n",
      "Precision score is 0.9203069657615112\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "refactoringsInvolved0.133 +/- 0.002\n",
      "startLine0.128 +/- 0.002\n",
      "qtyOfCommits0.118 +/- 0.002\n",
      "classAssignmentsQty0.085 +/- 0.002\n",
      "authorOwnership0.082 +/- 0.002\n",
      "classTCC0.081 +/- 0.002\n",
      "classStringLiteralsQty0.066 +/- 0.002\n",
      "classRfc0.057 +/- 0.002\n",
      "classCbo0.057 +/- 0.002\n",
      "classVariablesQty0.052 +/- 0.002\n",
      "=================================\n",
      "Best Model is finding for Rename Method\n",
      "data/renamemethod.ftr\n",
      "0    66803\n",
      "1    36929\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (103732, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    36929\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    36929\n",
      "1    36929\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 23.401641368865967\n",
      "The validation time: 0.00983119010925293\n",
      "The accuracy of the model 0.9119956674790144\n",
      "Recall score is 0.9089049502250103\n",
      "Precision score is 0.9133890639989036\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "classWmc0.192 +/- 0.002\n",
      "qtyOfCommits0.139 +/- 0.001\n",
      "startLine0.116 +/- 0.001\n",
      "classNumberOfMethods0.098 +/- 0.001\n",
      "classLcom0.089 +/- 0.001\n",
      "classUniqueWordsQty0.084 +/- 0.000\n",
      "classCbo0.055 +/- 0.001\n",
      "classLCC0.055 +/- 0.001\n",
      "refactoringsInvolved0.053 +/- 0.001\n",
      "classTCC0.049 +/- 0.000\n",
      "=================================\n",
      "Best Model is finding for Extract And Move Method\n",
      "data/extractandmovemethod.ftr\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (75440, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    8637\n",
      "1    8637\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 5.198047876358032\n",
      "The validation time: 0.00395965576171875\n",
      "The accuracy of the model 0.8714905933429812\n",
      "Recall score is 0.8685581933989577\n",
      "Precision score is 0.8736167734420501\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "methodLoc0.140 +/- 0.002\n",
      "methodRfc0.092 +/- 0.002\n",
      "startLine0.091 +/- 0.002\n",
      "classNumberOfPublicMethods0.084 +/- 0.002\n",
      "qtyOfCommits0.075 +/- 0.002\n",
      "classCbo0.043 +/- 0.001\n",
      "classUniqueWordsQty0.042 +/- 0.001\n",
      "classTCC0.042 +/- 0.001\n",
      "classStringLiteralsQty0.041 +/- 0.001\n",
      "refactoringsInvolved0.040 +/- 0.001\n",
      "=================================\n",
      "Best Model is finding for Change Return Type\n",
      "data/changereturntype.ftr\n",
      "0    66803\n",
      "1    58308\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (125111, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    58308\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    58308\n",
      "1    58308\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 38.99399924278259\n",
      "The validation time: 0.012609720230102539\n",
      "The accuracy of the model 0.9217115417595609\n",
      "Recall score is 0.9403725626740947\n",
      "Precision score is 0.90447086403215\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "classWmc0.203 +/- 0.001\n",
      "classStringLiteralsQty0.107 +/- 0.001\n",
      "classLoc0.100 +/- 0.001\n",
      "qtyOfAuthors0.091 +/- 0.001\n",
      "qtyOfCommits0.088 +/- 0.001\n",
      "refactoringsInvolved0.087 +/- 0.001\n",
      "qtyMajorAuthors0.080 +/- 0.001\n",
      "classRfc0.078 +/- 0.000\n",
      "classUniqueWordsQty0.078 +/- 0.001\n",
      "classNumbersQty0.075 +/- 0.000\n",
      "=================================\n",
      "Best Model is finding for Move And Inline Method\n",
      "data/moveandinlinemethod.ftr\n",
      "0    66803\n",
      "1     3751\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (70554, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     3751\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    3751\n",
      "1    3751\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 1.94321608543396\n",
      "The validation time: 0.0022470951080322266\n",
      "The accuracy of the model 0.9073950699533644\n",
      "Recall score is 0.9214380825565912\n",
      "Precision score is 0.8963730569948186\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "startLine0.208 +/- 0.004\n",
      "authorOwnership0.124 +/- 0.003\n",
      "classCbo0.110 +/- 0.003\n",
      "classTCC0.093 +/- 0.003\n",
      "refactoringsInvolved0.075 +/- 0.002\n",
      "classLcom0.053 +/- 0.002\n",
      "methodLoc0.044 +/- 0.002\n",
      "classNumberOfStaticFields0.042 +/- 0.002\n",
      "qtyMajorAuthors0.041 +/- 0.002\n",
      "qtyOfCommits0.040 +/- 0.001\n",
      "=================================\n",
      "Best Model is finding for Move And Rename Method\n",
      "data/moveandrenamemethod.ftr\n",
      "0    66803\n",
      "1     4826\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (71629, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     4826\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    4826\n",
      "1    4826\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 2.2439889907836914\n",
      "The validation time: 0.0022449493408203125\n",
      "The accuracy of the model 0.8508544795442776\n",
      "Recall score is 0.8404145077720208\n",
      "Precision score is 0.8582010582010582\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "startLine0.186 +/- 0.004\n",
      "qtyOfCommits0.138 +/- 0.004\n",
      "refactoringsInvolved0.098 +/- 0.003\n",
      "methodLoc0.085 +/- 0.003\n",
      "authorOwnership0.066 +/- 0.003\n",
      "classLoc0.065 +/- 0.002\n",
      "classNumberOfMethods0.065 +/- 0.002\n",
      "classCbo0.043 +/- 0.002\n",
      "classNumberOfPublicMethods0.039 +/- 0.002\n",
      "methodVariablesQty0.032 +/- 0.002\n",
      "=================================\n",
      "Best Model is finding for Change Parameter Type\n",
      "data/changeparametertype.ftr\n",
      "1    84221\n",
      "0    66803\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (151024, 69)\n",
      "Number of sample in different classes before sampling\n",
      "1    84221\n",
      "0    66803\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    66803\n",
      "1    66803\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 53.25326418876648\n",
      "The validation time: 0.015264034271240234\n",
      "The accuracy of the model 0.9379537459770976\n",
      "Recall score is 0.9502476361999099\n",
      "Precision score is 0.9271489237077171\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "methodParametersQty0.144 +/- 0.001\n",
      "refactoringsInvolved0.129 +/- 0.001\n",
      "classUniqueWordsQty0.106 +/- 0.001\n",
      "startLine0.102 +/- 0.001\n",
      "qtyOfCommits0.102 +/- 0.001\n",
      "classLcom0.091 +/- 0.001\n",
      "authorOwnership0.071 +/- 0.001\n",
      "classCbo0.070 +/- 0.001\n",
      "classWmc0.041 +/- 0.000\n",
      "classLoc0.041 +/- 0.000\n",
      "=================================\n",
      "Best Model is finding for Split Parameter\n",
      "data/splitparameter.ftr\n",
      "0    66803\n",
      "1      390\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (67193, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1      390\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    390\n",
      "1    390\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 0.6769001483917236\n",
      "The validation time: 0.007314920425415039\n",
      "The accuracy of the model 0.8717948717948718\n",
      "Recall score is 0.8974358974358975\n",
      "Precision score is 0.8536585365853658\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methodParametersQty0.202 +/- 0.013\n",
      "startLine0.146 +/- 0.015\n",
      "classNumberOfPublicMethods0.093 +/- 0.008\n",
      "classLoc0.082 +/- 0.009\n",
      "methodRfc0.073 +/- 0.007\n",
      "classReturnQty0.067 +/- 0.008\n",
      "authorOwnership0.051 +/- 0.005\n",
      "classNumberOfDefaultFields0.048 +/- 0.006\n",
      "methodLoc0.020 +/- 0.004\n",
      "classMathOperationsQty0.019 +/- 0.005\n",
      "=================================\n",
      "Best Model is finding for Merge Parameter\n",
      "data/mergeparameter.ftr\n",
      "0    66803\n",
      "1     1213\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (68016, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     1213\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    1213\n",
      "1    1213\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The training time: 0.9277276992797852\n",
      "The validation time: 0.002279043197631836\n",
      "The accuracy of the model 0.911522633744856\n",
      "Recall score is 0.9324894514767933\n",
      "Precision score is 0.8911290322580645\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "=================================\n",
      "methodParametersQty0.322 +/- 0.007\n",
      "authorOwnership0.067 +/- 0.004\n",
      "startLine0.051 +/- 0.004\n",
      "classNumberOfStaticMethods0.046 +/- 0.003\n",
      "classNumberOfMethods0.045 +/- 0.004\n",
      "qtyOfCommits0.036 +/- 0.003\n",
      "methodLoc0.013 +/- 0.002\n",
      "classLCC0.008 +/- 0.001\n",
      "classNosi0.005 +/- 0.001\n",
      "classTCC0.005 +/- 0.001\n"
     ]
    }
   ],
   "source": [
    "train_model_method_refactoring_1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f64eb8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'classNumberOfAbstractMethods'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "abfb0fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Best Model is finding for Extract And Move Method\n",
      "data/extractandmovemethod.ftr\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (75440, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    8637\n",
      "1    8637\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "The accuracy of the model 0.9328509406657018\n",
      "Recall score is 0.937463810075275\n",
      "Precision score is 0.9288582903040734\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n",
      "Feature Importance\n",
      "{'importances_mean': array([0.00000000e+00, 0.00000000e+00, 3.69057095e-04, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 2.17092409e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 5.78913091e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       2.17092409e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       5.06548954e-05, 0.00000000e+00, 4.34184818e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 5.32600043e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 7.23641363e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.51689703e-03, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 5.06548954e-05, 4.34184818e-04,\n",
      "       0.00000000e+00, 9.21919097e-03, 2.89456545e-04, 3.61820682e-05,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.08546205e-04,\n",
      "       1.59201100e-04]), 'importances_std': array([0.00000000e+00, 0.00000000e+00, 9.94842397e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.31614132e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 2.89456545e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.31614132e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.31614132e-05, 0.00000000e+00, 3.54510419e-05, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.51841545e-04, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 1.62457083e-04, 0.00000000e+00,\n",
      "       0.00000000e+00, 0.00000000e+00, 3.31614132e-05, 8.56224008e-05,\n",
      "       0.00000000e+00, 5.73642700e-04, 1.16683664e-04, 3.61820682e-05,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.67164372e-05,\n",
      "       9.03827773e-05]), 'importances': array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [4.34184818e-04, 4.34184818e-04, 3.61820682e-04, 4.34184818e-04,\n",
      "        2.17092409e-04, 1.44728273e-04, 3.61820682e-04, 4.34184818e-04,\n",
      "        4.34184818e-04, 4.34184818e-04],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [7.23641363e-05, 0.00000000e+00, 0.00000000e+00, 7.23641363e-05,\n",
      "        7.23641363e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [7.23641363e-05, 0.00000000e+00, 7.23641363e-05, 7.23641363e-05,\n",
      "        7.23641363e-05, 7.23641363e-05, 7.23641363e-05, 0.00000000e+00,\n",
      "        7.23641363e-05, 7.23641363e-05],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 7.23641363e-05, 0.00000000e+00, 7.23641363e-05,\n",
      "        0.00000000e+00, 0.00000000e+00, 7.23641363e-05, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 7.23641363e-05, 7.23641363e-05, 7.23641363e-05,\n",
      "        7.23641363e-05, 7.23641363e-05, 0.00000000e+00, 7.23641363e-05,\n",
      "        0.00000000e+00, 7.23641363e-05],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [7.23641363e-05, 7.23641363e-05, 7.23641363e-05, 7.23641363e-05,\n",
      "        7.23641363e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        7.23641363e-05, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [5.86149504e-03, 4.84839713e-03, 5.49967436e-03, 5.28258195e-03,\n",
      "        4.77603300e-03, 5.42731023e-03, 5.06548954e-03, 5.42731023e-03,\n",
      "        5.86149504e-03, 5.21021782e-03],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [7.23641363e-05, 7.23641363e-05, 7.23641363e-05, 7.23641363e-05,\n",
      "        7.23641363e-05, 7.23641363e-05, 7.23641363e-05, 7.23641363e-05,\n",
      "        7.23641363e-05, 7.23641363e-05],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [3.40111441e-03, 3.54584268e-03, 3.40111441e-03, 3.54584268e-03,\n",
      "        3.90766336e-03, 3.40111441e-03, 3.32875027e-03, 3.40111441e-03,\n",
      "        3.61820682e-03, 3.61820682e-03],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 7.23641363e-05, 0.00000000e+00, 7.23641363e-05,\n",
      "        7.23641363e-05, 7.23641363e-05, 0.00000000e+00, 7.23641363e-05,\n",
      "        7.23641363e-05, 7.23641363e-05],\n",
      "       [4.34184818e-04, 3.61820682e-04, 5.06548954e-04, 3.61820682e-04,\n",
      "        6.51277227e-04, 4.34184818e-04, 4.34184818e-04, 3.61820682e-04,\n",
      "        4.34184818e-04, 3.61820682e-04],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [9.40733772e-03, 1.02757074e-02, 9.04551704e-03, 8.82842463e-03,\n",
      "        9.69679427e-03, 8.97315291e-03, 8.61133222e-03, 9.11788118e-03,\n",
      "        8.32187568e-03, 9.91388668e-03],\n",
      "       [1.44728273e-04, 4.34184818e-04, 2.17092409e-04, 2.89456545e-04,\n",
      "        1.44728273e-04, 4.34184818e-04, 4.34184818e-04, 2.89456545e-04,\n",
      "        1.44728273e-04, 3.61820682e-04],\n",
      "       [7.23641363e-05, 7.23641363e-05, 0.00000000e+00, 0.00000000e+00,\n",
      "        7.23641363e-05, 0.00000000e+00, 7.23641363e-05, 7.23641363e-05,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [7.23641363e-05, 1.44728273e-04, 2.17092409e-04, 7.23641363e-05,\n",
      "        7.23641363e-05, 7.23641363e-05, 1.44728273e-04, 0.00000000e+00,\n",
      "        2.17092409e-04, 7.23641363e-05],\n",
      "       [2.89456545e-04, 0.00000000e+00, 7.23641363e-05, 7.23641363e-05,\n",
      "        2.89456545e-04, 2.17092409e-04, 1.44728273e-04, 1.44728273e-04,\n",
      "        1.44728273e-04, 2.17092409e-04]])}\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "def train_model_method_refactoring():\n",
    "    non_refactored_file_path = 'data/nonrefactoreddata.ftr'\n",
    "    for method_refactoring in METHOD_LEVEL_REFACTORINGS:\n",
    "        print(\"=================================\")\n",
    "        print(\"Best Model is finding for\", method_refactoring)\n",
    "        \n",
    "        # PICK first refactoring metric\n",
    "        refactored_file_path = ''.join(['data/', ''.join(method_refactoring.lower().split()), '.ftr'])\n",
    "        print(refactored_file_path)\n",
    "        (x, y) = load_cache_data_and_preprocess_it(refactored_file_path, non_refactored_file_path)\n",
    "        \n",
    "        print(\"The shape of sample is\", x.shape)\n",
    "        print(\"Number of sample in different classes before sampling\")\n",
    "        print(y.value_counts())\n",
    "        \n",
    "        undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "        X_over, y_over = undersample.fit_resample(x, y)\n",
    "        \n",
    "        print(\"Number of sample in different classes after sampling\")\n",
    "        print(y_over.value_counts())\n",
    "        \n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(X_over, y_over, test_size=0.20, random_state=42)\n",
    "        \n",
    "        randomizedCVModel = get_random_forest_tree_model_random_cv()\n",
    "        \n",
    "        randomizedCVModel.fit(X_train, y_train)\n",
    "        \n",
    "        best_estimator = randomizedCVModel.best_estimator_\n",
    "        \n",
    "        print(\"The accuracy of the model\", best_estimator.score(X_test, y_test))\n",
    "        print(\"Recall score is\", recall_score(y_test, best_estimator.predict(X_test)))\n",
    "        print(\"Precision score is\", precision_score(y_test, best_estimator.predict(X_test)))\n",
    "              \n",
    "        print(search.best_estimator_)\n",
    "        print(search.best_params_)\n",
    "        print(search.best_score_)\n",
    "        \n",
    "        print(\"Feature Importance\")\n",
    "        result = permutation_importance(best_estimator, X_train, y_train, n_repeats=10,random_state=0)\n",
    "        print(result)\n",
    "        print(\"=================================\")\n",
    "        break \n",
    "        \n",
    "train_model_method_refactoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "84bf7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_method_refactoring_3():\n",
    "    non_refactored_file_path = 'data/nonrefactoreddata.ftr'\n",
    "    for method_refactoring in METHOD_LEVEL_REFACTORINGS:\n",
    "        print(\"=================================\")\n",
    "        print(\"Best Model is finding for\", method_refactoring)\n",
    "        \n",
    "        # PICK first refactoring metric\n",
    "        refactored_file_path = ''.join(['data/', ''.join(method_refactoring.lower().split()), '.ftr'])\n",
    "        print(refactored_file_path)\n",
    "        (x, y) = load_cache_data_and_preprocess_it(refactored_file_path, non_refactored_file_path)\n",
    "        \n",
    "        print(\"The shape of sample is\", x.shape)\n",
    "        print(\"Number of sample in different classes before sampling\")\n",
    "        print(y.value_counts())\n",
    "        \n",
    "        undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "        X_over, y_over = undersample.fit_resample(x, y)\n",
    "        \n",
    "        print(\"Number of sample in different classes after sampling\")\n",
    "        print(y_over.value_counts())\n",
    "        \n",
    "        (X_train, X_test, y_train, y_test) = train_test_split(X_over, y_over, test_size=0.20, random_state=42)\n",
    "        \n",
    "        logModel = get_logistic_regression_model_random_cv()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        logModel.fit(X_train, y_train)\n",
    "        print(\"The training time:\", time.time() - t0)\n",
    "        \n",
    "        best_estimator = logModel.best_estimator_\n",
    "        \n",
    "        print(\"The best estimator is\", best_estimator)\n",
    "        \n",
    "        t1 = time.time()\n",
    "        best_estimator.score(X_test, y_test)\n",
    "        print(\"The validation time:\", time.time() - t1)\n",
    "        \n",
    "        \n",
    "        print(\"The accuracy of the model\", best_estimator.score(X_test, y_test))\n",
    "        print(\"Recall score is\", recall_score(y_test, best_estimator.predict(X_test)))\n",
    "        print(\"Precision score is\", precision_score(y_test, best_estimator.predict(X_test)))\n",
    "              \n",
    "        \n",
    "        # print(\"Feature Importance\")\n",
    "        # result = permutation_importance(best_estimator, X_train, y_train, n_repeats=10,random_state=0)\n",
    "        # print(result)\n",
    "        print(\"=================================\")\n",
    "         \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c6fefa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Best Model is finding for Extract And Move Method\n",
      "data/extractandmovemethod.ftr\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (75440, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    8637\n",
      "1    8637\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 52.104833126068115\n",
      "The best estimator is LogisticRegression(C=43.642729943108215, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.0028569698333740234\n",
      "The accuracy of the model 0.7539797395079595\n",
      "Recall score is 0.7782281412854661\n",
      "Precision score is 0.7421314191054665\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Extract Method\n",
      "data/extractmethod.ftr\n",
      "0    66803\n",
      "1    29946\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (96749, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    29946\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    29946\n",
      "1    29946\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 222.261803150177\n",
      "The best estimator is LogisticRegression(C=92.3142004705179, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.00617527961730957\n",
      "The accuracy of the model 0.784957008097504\n",
      "Recall score is 0.8417836498761354\n",
      "Precision score is 0.7590469099032018\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Inline Method\n",
      "data/inlinemethod.ftr\n",
      "0    66803\n",
      "1     7098\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (73901, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     7098\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    7098\n",
      "1    7098\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 43.351651668548584\n",
      "The best estimator is LogisticRegression(C=11.747787191855886, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.0031321048736572266\n",
      "The accuracy of the model 0.6704225352112676\n",
      "Recall score is 0.6636107193229901\n",
      "Precision score is 0.6721428571428572\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Move Method\n",
      "data/movemethod.ftr\n",
      "0    66803\n",
      "1    23835\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (90638, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    23835\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    23835\n",
      "1    23835\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 196.11906504631042\n",
      "The best estimator is LogisticRegression(C=96.11762373027274, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.005357980728149414\n",
      "The accuracy of the model 0.6985525487728131\n",
      "Recall score is 0.6463035825222614\n",
      "Precision score is 0.7280149288546769\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Pull Up Method\n",
      "data/pullupmethod.ftr\n",
      "0    66803\n",
      "1    14062\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (80865, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    14062\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    14062\n",
      "1    14062\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 109.31514096260071\n",
      "The best estimator is LogisticRegression(C=80.42722269942684, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.004240989685058594\n",
      "The accuracy of the model 0.7249777777777778\n",
      "Recall score is 0.67889575009081\n",
      "Precision score is 0.7381516587677726\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Push Down Method\n",
      "data/pushdownmethod.ftr\n",
      "0    66803\n",
      "1     8039\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (74842, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     8039\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    8039\n",
      "1    8039\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 60.65658903121948\n",
      "The best estimator is LogisticRegression(C=71.67244715342615, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.0032148361206054688\n",
      "The accuracy of the model 0.7369402985074627\n",
      "Recall score is 0.6858024691358025\n",
      "Precision score is 0.7672651933701657\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Rename Method\n",
      "data/renamemethod.ftr\n",
      "0    66803\n",
      "1    36929\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (103732, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    36929\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    36929\n",
      "1    36929\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 405.3032410144806\n",
      "The best estimator is LogisticRegression(C=84.19273471358763, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.008512020111083984\n",
      "The accuracy of the model 0.6809504467912266\n",
      "Recall score is 0.583799263602891\n",
      "Precision score is 0.7204644900706832\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Extract And Move Method\n",
      "data/extractandmovemethod.ftr\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (75440, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     8637\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    8637\n",
      "1    8637\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 68.61100172996521\n",
      "The best estimator is LogisticRegression(C=95.48512107683783, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.004611015319824219\n",
      "The accuracy of the model 0.7452966714905933\n",
      "Recall score is 0.7735958309206716\n",
      "Precision score is 0.7320547945205479\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Change Return Type\n",
      "data/changereturntype.ftr\n",
      "0    66803\n",
      "1    58308\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (125111, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1    58308\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    58308\n",
      "1    58308\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 590.4755721092224\n",
      "The best estimator is LogisticRegression(C=76.98847033211139, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.017905235290527344\n",
      "The accuracy of the model 0.7457125707425828\n",
      "Recall score is 0.7343314763231198\n",
      "Precision score is 0.745558992487848\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Move And Inline Method\n",
      "data/moveandinlinemethod.ftr\n",
      "0    66803\n",
      "1     3751\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (70554, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     3751\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    3751\n",
      "1    3751\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 22.86668372154236\n",
      "The best estimator is LogisticRegression(C=96.39622825592856, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.004361867904663086\n",
      "The accuracy of the model 0.6888740839440373\n",
      "Recall score is 0.677762982689747\n",
      "Precision score is 0.6934604904632152\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Move And Rename Method\n",
      "data/moveandrenamemethod.ftr\n",
      "0    66803\n",
      "1     4826\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (71629, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     4826\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    4826\n",
      "1    4826\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 42.686026096343994\n",
      "The best estimator is LogisticRegression(C=22.776828394194695, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.004266977310180664\n",
      "The accuracy of the model 0.6462972553081305\n",
      "Recall score is 0.48601036269430054\n",
      "Precision score is 0.7149390243902439\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Change Parameter Type\n",
      "data/changeparametertype.ftr\n",
      "1    84221\n",
      "0    66803\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (151024, 69)\n",
      "Number of sample in different classes before sampling\n",
      "1    84221\n",
      "0    66803\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    66803\n",
      "1    66803\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 704.1615979671478\n",
      "The best estimator is LogisticRegression(C=80.59347212924007, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.014760971069335938\n",
      "The accuracy of the model 0.7816031734151635\n",
      "Recall score is 0.7886087348041423\n",
      "Precision score is 0.776833234772324\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Split Parameter\n",
      "data/splitparameter.ftr\n",
      "0    66803\n",
      "1      390\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (67193, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1      390\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    390\n",
      "1    390\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 2.0720057487487793\n",
      "The best estimator is LogisticRegression(C=95.76894157179753, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.003196239471435547\n",
      "The accuracy of the model 0.6858974358974359\n",
      "Recall score is 0.5641025641025641\n",
      "Precision score is 0.7457627118644068\n",
      "=================================\n",
      "=================================\n",
      "Best Model is finding for Merge Parameter\n",
      "data/mergeparameter.ftr\n",
      "0    66803\n",
      "1     1213\n",
      "Name: refactored, dtype: int64\n",
      "The shape of sample is (68016, 69)\n",
      "Number of sample in different classes before sampling\n",
      "0    66803\n",
      "1     1213\n",
      "Name: refactored, dtype: int64\n",
      "Number of sample in different classes after sampling\n",
      "0    1213\n",
      "1    1213\n",
      "Name: refactored, dtype: int64\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 15 is smaller than n_iter=100. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training time: 6.373842000961304\n",
      "The best estimator is LogisticRegression(C=55.6270148855751, max_iter=1000, random_state=20,\n",
      "                   solver='saga')\n",
      "The validation time: 0.0032351016998291016\n",
      "The accuracy of the model 0.6152263374485597\n",
      "Recall score is 0.5021097046413502\n",
      "Precision score is 0.6329787234042553\n",
      "=================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "train_model_method_refactoring_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee15bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d5547e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
      "                   estimator=LogisticRegression(random_state=20, solver='saga'),\n",
      "                   n_iter=100, n_jobs=-1,\n",
      "                   param_distributions={'C': [29.544703196961578,\n",
      "                                              1.81665029382471,\n",
      "                                              93.98997453592514,\n",
      "                                              13.192479504371025,\n",
      "                                              10.562249798760876],\n",
      "                                        'max_iter': [100, 500, 1000, 2000, 5000,\n",
      "                                                     10000]},\n",
      "                   scoring='accuracy', verbose=1)\n"
     ]
    }
   ],
   "source": [
    "print(get_logistic_regression_model_random_cv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7baa4ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(criterion='entropy', max_depth=16, max_features='log2',\n",
      "                       min_samples_split=4, random_state=20)\n",
      "{'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 16, 'criterion': 'entropy'}\n",
      "0.8991330656705351\n"
     ]
    }
   ],
   "source": [
    "print(search.best_estimator_)\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "63c768aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9026356589147286\n"
     ]
    }
   ],
   "source": [
    "print(search.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "44ee9899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.10230930e-03 1.25422719e-02 1.87025782e-02 8.26570899e-03\n",
      " 1.69277184e-03 1.08887474e-02 3.91618629e-02 8.96882293e-03\n",
      " 9.14782029e-03 6.66712156e-03 4.33803501e-03 6.54343324e-03\n",
      " 5.77972356e-04 5.59271337e-03 5.76159130e-03 7.96584203e-03\n",
      " 9.37898424e-03 6.65229101e-03 8.94126397e-03 7.98527144e-03\n",
      " 6.56953824e-03 3.86973463e-03 5.98182543e-03 2.35362368e-03\n",
      " 1.49884631e-02 4.61586016e-03 4.69508665e-03 0.00000000e+00\n",
      " 2.24338439e-03 8.40676841e-03 7.20806304e-03 1.65596338e-02\n",
      " 1.49561414e-02 1.29034555e-02 2.87597234e-03 5.53578894e-03\n",
      " 2.15611458e-02 1.40223034e-02 2.49129540e-02 1.14726178e-02\n",
      " 3.42480570e-03 1.86560218e-03 4.88305539e-03 1.05240866e-01\n",
      " 1.60346493e-03 6.97721227e-05 1.48882329e-01 1.13845939e-03\n",
      " 1.21197920e-03 3.10391197e-03 1.09766747e-03 3.57871976e-03\n",
      " 7.47084164e-04 2.24702025e-03 2.07470479e-02 2.48449745e-03\n",
      " 0.00000000e+00 4.48335872e-04 8.78219552e-03 1.48258771e-02\n",
      " 4.49207243e-02 6.18844973e-02 1.16854241e-02 1.93919313e-02\n",
      " 1.67866096e-02 3.34236183e-02 4.98709560e-02 4.08464100e-02\n",
      " 2.71973637e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96749, 69)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(search.best_estimator_.feature_importances_)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5ae5861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "faa5aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_over, y_over = undersample.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e1957a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29946\n",
       "1    29946\n",
       "Name: refactored, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over.shape\n",
    "y_over.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
